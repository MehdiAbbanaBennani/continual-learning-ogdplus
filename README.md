# Continual Learning with OGD and OGD+

This is the official implementation of the [Generalisation Guarantees for Continual Learning with Orthogonal Gradient
 Descent](https://arxiv.org/abs/2006.11942) in PyTorch.
 
## Requirements
 PyTorch >= 1.5.0 

## Reproducibility
In order to replicate the results of the paper, please run the scripts in the scripts directory.
 
## Questions/ Bugs
- For questions or bugs, please feel free to contact Mehdi Abbana Bennani or to raise an issue on Github :)

## Citation
If this repository helps your work, please cite:

```
@article{bennani2020generalisation,
    title={Generalisation Guarantees for Continual Learning with Orthogonal Gradient Descent},
    author={Mehdi Abbana Bennani and Masashi Sugiyama},
    year={2020},
    journal={arXiv preprint arXiv:2006.11942, 2020},
}
```


## Licence
A substantial part of this source code was initially forked from the repository [GT-RIPL/Continual-Learning-Benchmark
](https://github.com/GT-RIPL/Continual-Learning-Benchmark). The associated Licence is also provided in the root
 directory.  
 
 This source code is released under The MIT License found in the LICENSE file in the root directory of this source tree. 